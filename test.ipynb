{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test my IDEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODEL(nn.Module):\n",
    "\tdef\t__init__(self, model_dict: dict[str, any], forward_order: list[str] = None):\n",
    "\t\tsuper().__init__()\n",
    "\t\tfor key, value in model_dict.items():\n",
    "\t\t\tself.add_module(key, value)\n",
    "\t\t\n",
    "\t\tself.forward_order = forward_order or list(model_dict.keys())\n",
    "\n",
    "\tdef\tforward(self, x):\n",
    "\t\tfor module_name in self.forward_order:\n",
    "\t\t\tmodule = getattr(self, module_name)\n",
    "\t\t\tx = module(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "\t\"conv1\": nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "\t\"relu1\": nn.ReLU(),\n",
    "\t\"pool1\": nn.MaxPool2d(2, 2),\n",
    "\t\"conv2\": nn.Conv2d(16, 32, 3, padding=1),\n",
    "\t\"relu2\": nn.ReLU(),\n",
    "\t\"pool2\": nn.MaxPool2d(2, 2),\n",
    "\t\"flatten\": nn.Flatten(),\n",
    "\t\"fc1\": nn.Linear(32 * 8 * 8, 128),\n",
    "\t\"relu3\": nn.ReLU(),\n",
    "\t\"fc2\": nn.Linear(128, 4),\n",
    "}\n",
    "\n",
    "forward_order = [\n",
    "\t\"conv1\", \"relu1\", \"pool1\",\n",
    "\t\"conv2\", \"relu2\", \"pool2\", \n",
    "\t\"flatten\", \"fc1\", \"relu3\", \"fc2\"\n",
    "]\n",
    "\n",
    "model = MODEL(model_dict, forward_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0136, -0.0220, -0.0751, -0.0288]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3, 32, 32)\n",
    "output = model.forward(dummy_input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test more IDEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODEL(nn.Module):\n",
    "\tdef __init__(self, model_dict: dict[str, any], computation_graph: list[tuple[str, list[str]]] = None):\n",
    "\t\tsuper().__init__()\n",
    "\t\tfor key, value in model_dict.items():\n",
    "\t\t\tself.add_module(key, value)\n",
    "\n",
    "\t\tself.computation_graph = computation_graph\n",
    "\t\tif computation_graph:\n",
    "\t\t\tself.forward_order = self._build_forward_order(computation_graph)\n",
    "\t\telse:\n",
    "\t\t\tself.forward_order = list(model_dict.keys())\n",
    "\t\t\n",
    "\tdef _build_forward_order(self, graph):\n",
    "\t\t\"\"\"Build execution order from computation graph using topological sort\"\"\"\n",
    "\t\tadj = {node: [] for node, _ in graph}\n",
    "\t\tindegree = {node: 0 for node, _ in graph}\n",
    "\n",
    "\t\tfor node, next_nodes in graph:\n",
    "\t\t\tadj[node] = next_nodes\n",
    "\t\t\tfor next_node in next_nodes:\n",
    "\t\t\t\tindegree[next_node] = indegree.get(next_node, 0) + 1\n",
    "\t\t\n",
    "\t\t# Find starting nodes (indegree = 0)\n",
    "\t\tqueue = [node for node in indegree if indegree[node] == 0]\n",
    "\t\torder = []\n",
    "\n",
    "\t\twhile queue:\n",
    "\t\t\tnode = queue.pop(0)\n",
    "\t\t\torder.append(node)\n",
    "\t\t\tfor neighbor in adj[node]:\n",
    "\t\t\t\tindegree[neighbor] -= 1\n",
    "\t\t\t\tif indegree[neighbor] == 0:\n",
    "\t\t\t\t\tqueue.append(neighbor)\n",
    "\t\t\n",
    "\t\treturn order\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tfor module_name in self.forward_order:\n",
    "\t\t\tmodule = getattr(self, module_name)\n",
    "\t\t\tx = module(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0279,  0.1236, -0.0747,  0.0309]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = {\n",
    "\t\"conv1\": nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "\t\"relu1\": nn.ReLU(),\n",
    "\t\"pool1\": nn.MaxPool2d(2, 2),\n",
    "\t\"conv2\": nn.Conv2d(16, 32, 3, padding=1),\n",
    "\t\"relu2\": nn.ReLU(),\n",
    "\t\"pool2\": nn.MaxPool2d(2, 2),\n",
    "\t\"flatten\": nn.Flatten(),\n",
    "\t\"fc1\": nn.Linear(32 * 8 * 8, 128),\n",
    "\t\"relu3\": nn.ReLU(),\n",
    "\t\"fc2\": nn.Linear(128, 4),\n",
    "}\n",
    "\n",
    "computation_graph = [\n",
    "\t(\"conv1\", [\"relu1\"]),\n",
    "\t(\"relu1\", [\"pool1\"]),\n",
    "\t(\"pool1\", [\"conv2\"]),\n",
    "\t(\"conv2\", [\"relu2\"]),\n",
    "\t(\"relu2\", [\"pool2\"]),\n",
    "\t(\"pool2\", [\"flatten\"]),\n",
    "\t(\"flatten\", [\"fc1\"]),\n",
    "\t(\"fc1\", [\"relu3\"]),\n",
    "\t(\"relu3\", [\"fc2\"]),\n",
    "\t(\"fc2\", []),\n",
    "]\n",
    "\n",
    "model = MODEL(model_dict, computation_graph)\n",
    "dummy_input = torch.randn(1, 3, 32, 32)\n",
    "output = model.forward(dummy_input)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
